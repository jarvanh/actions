name: openlist

on:
  schedule:
    # - cron: "0 1,7,13,19 * * *"
    - cron: "*/5 * * * *"
  workflow_dispatch:
  # workflow_run:
  #   workflows:
  #     - t
  #   types:
  #     - completed  # 工作流完成后触发
  watch:
    # types: started

jobs:
  build:
    concurrency: openlist-singleton
    runs-on: ubuntu-latest
    # timeout-minutes: 60
    steps:
      - name: rclone-install
        run: |
          curl -O https://beta.rclone.org/rclone-beta-latest-linux-amd64.zip
          unzip rclone-*-amd64.zip
          cd rclone-*-linux-amd64
          sudo mv rclone /usr/bin
          sudo chmod +x /usr/bin/rclone
      - name: rclone-config
        env:
          RCLONE_CONFIG: ${{ secrets.RCLONE }}
        run: |
          mkdir -p ~/.config/rclone/
          cat << EOF > ~/.config/rclone/rclone.conf
          $RCLONE_CONFIG
          EOF
      - name: rclone-run
        run: |
          echo "==========onedrive==========="
          rclone lsf onedrive:
          echo "==========dropbox==========="
          rclone lsf dropbox:

          sudo apt-get install fuse3
          sudo mkdir -p /dropbox
          sudo nohup rclone mount dropbox: /dropbox --allow-non-empty --no-gzip-encoding --umask 000 --allow-other --attr-timeout 10m --vfs-cache-mode full --vfs-cache-max-age 5m --vfs-read-chunk-size-limit 10G --buffer-size 100M --vfs-cache-max-size 10G &
      - name: Run openlist container
        run: docker run -d --restart=unless-stopped -v /dropbox/self-hosted/openlist/data:/opt/openlist/data -p 5244:5244 -e PUID=0 -e PGID=0 -e UMASK=022 --name="openlist" openlistteam/openlist:latest
      - name: sleep
        run: |
          sudo sleep 1m      
      - name: Verify docker container is running
        run: docker ps

      - name: Split large videos
        run: |
          # 安装依赖
          echo "Installing ffmpeg, jq, and coreutils..."
          sudo apt-get update && sudo apt-get install -y ffmpeg jq coreutils
          
          # 定义参数 - 调整为更接近4GB但确保安全
          LIMIT_BYTES=3990000000  # 3.99GB，更接近4GB但留有安全边际
          REMOTE_PATHS=("onedrive:0/照片/相簿/marry" "onedrive:1")
          TEMP_BASE_DIR="temp_split_videos"
          mkdir -p "$TEMP_BASE_DIR"
      
          # 处理每个远程路径
          for REMOTE_PATH in "${REMOTE_PATHS[@]}"; do
            echo "-----------------------------------------------------"
            echo "Processing remote path: ${REMOTE_PATH}"
            TEMP_DIR="${TEMP_BASE_DIR}/${REMOTE_PATH//:/_}"
            mkdir -p "$TEMP_DIR"
      
            echo "Searching for large video files (接近4GB) in ${REMOTE_PATH}..."
            
            # 降低阈值到3.8GB，确保捕获所有接近4GB的文件
            rclone lsjson --recursive "${REMOTE_PATH}" --min-size 3800000000 | \
            jq -r '.[] | select((.Path | test("\\.(mp4|mkv|mov|avi|flv|webm)$"; "i")) and .IsDir == false) | "\(.Path)\t\(.Size)"' | \
            while IFS=$'\t' read -r video_file FILE_SIZE; do
                [ -z "$video_file" ] && continue
                
                echo "-----------------------------------------------------"
                echo "Found video: \"$video_file\" (Size: $(numfmt --to=iec $FILE_SIZE))"
      
                # 添加详细的大小检查
                SIZE_GB=$(echo "scale=2; $FILE_SIZE/1000000000" | bc -l 2>/dev/null || echo "0")
                echo "File size: ${SIZE_GB} GB ($FILE_SIZE bytes)"
      
                # 检查是否真的需要分割（接近4GB的文件）
                if [ "$FILE_SIZE" -lt 3800000000 ]; then
                    echo "File is smaller than 3.8GB, skipping."
                    continue
                fi
      
                # 对于接近4GB的文件，即使略小于4GB也进行处理（安全起见）
                if [ "$FILE_SIZE" -lt 4000000000 ]; then
                    echo "File is close to 4GB (${SIZE_GB} GB), processing for safety..."
                fi
      
              # 下载文件
              echo "Downloading..."
              rclone copy "${REMOTE_PATH}/${video_file}" "$TEMP_DIR" > /dev/null 2>&1 || {
                  echo "Error: Download failed for \"$video_file\". Skipping."
                  continue
              }
      
              LOCAL_FILE_NAME=$(basename -- "$video_file")
              LOCAL_FILE_PATH="${TEMP_DIR}/${LOCAL_FILE_NAME}"
              
              # 获取视频时长
              DURATION=$(ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "$LOCAL_FILE_PATH" 2>/dev/null)
              if ! [[ "$DURATION" =~ ^[0-9.]+$ ]]; then
                  echo "Error: Invalid duration for \"$video_file\". Skipping."
                  rm -f "$LOCAL_FILE_PATH"
                  continue
              fi
              
              # 计算分割参数 - 使用更接近4GB的限制
              NUM_PARTS=$(( (FILE_SIZE + LIMIT_BYTES - 1) / LIMIT_BYTES ))
              if [ "$NUM_PARTS" -le 1 ]; then
                  # 对于接近4GB但略小的文件，仍然分割为2部分以确保安全
                  if [ "$FILE_SIZE" -gt 3900000000 ]; then
                      echo "File is very close to 4GB, splitting into 2 parts for safety."
                      NUM_PARTS=2
                  else
                      echo "File does not require splitting. Skipping."
                      rm -f "$LOCAL_FILE_PATH"
                      continue
                  fi
              fi
              
              SEGMENT_DURATION=$(awk -v d="$DURATION" -v n="$NUM_PARTS" 'BEGIN {print d / n}')
              echo "Splitting into $NUM_PARTS parts (~${SEGMENT_DURATION}s each)"
      
              # 准备文件名
              BASENAME=$(basename -- "$video_file")
              FILENAME="${BASENAME%.*}"
              EXTENSION="${BASENAME##*.}"
      
              # 执行分割
              ffmpeg -i "$LOCAL_FILE_PATH" -c copy -map 0 -f segment \
                     -segment_time "$SEGMENT_DURATION" -reset_timestamps 1 \
                     -loglevel warning "${TEMP_DIR}/${FILENAME}_part%03d.${EXTENSION}" || {
                  echo "Error: Splitting failed for \"$video_file\". Cleaning up."
                  rm -f "${TEMP_DIR}/${FILENAME}_part"* 
                  rm -f "$LOCAL_FILE_PATH"
                  continue
              }
              
              # 上传分割文件并删除原始文件
              original_dir=$(dirname "$video_file")
              echo "Uploading parts to ${REMOTE_PATH}/${original_dir}/"
              rclone move "$TEMP_DIR" "${REMOTE_PATH}/${original_dir}/" \
                    --include "${FILENAME}_part*.*" --delete-empty-src-dirs > /dev/null 2>&1
              
              echo "Deleting original: ${REMOTE_PATH}/${video_file}"
              rclone delete "${REMOTE_PATH}/${video_file}" > /dev/null 2>&1
              rm -f "$LOCAL_FILE_PATH"
              echo "Successfully processed: $video_file"
      
            done
            
            # 清理当前路径的临时目录
            rm -rf "$TEMP_DIR"
          done
          
          # 最终清理
          rm -rf "$TEMP_BASE_DIR"
          echo "-----------------------------------------------------"
          echo "Video splitting completed for all paths."
      
      - name: Install 7z tool for compression and splitting
        run: |
          echo "Installing p7zip-full for 7z command..."
          # p7zip-full 包含了 7z 命令行工具
          sudo apt-get update && sudo apt-get install -y p7zip-full
          
      # ====================================================================
      # ================ 通用大文件压缩并分卷 ================
      # ====================================================================
      # - name: Compress and split large general files
      #   run: |
      #     # 1. 定义参数
      #     # 1. 定义参数
      #     VOLUME_SIZE="2g" # 明确改为分卷大小的变量
      #     REMOTE_PATH="onedrive:backup"
      #     TEMP_DIR="temp_compress_split" # 使用新的临时目录
      #     mkdir -p "$TEMP_DIR"
          
      #     # 定义需要排除的视频文件扩展名，以防止对视频文件进行二次处理
      #     VIDEO_EXTENSIONS="\\.(mp4|mkv|mov|avi|flv|webm)$"

      #     echo "Searching for non-video files larger than 4GB in ${REMOTE_PATH}..."
          
      #     # 2. 使用 rclone lsjson 查找并筛选大文件，排除视频文件
      #     rclone lsjson --recursive ${REMOTE_PATH} --min-size 4G | \
      #     jq --arg video_re "$VIDEO_EXTENSIONS" -r '
      #       .[] | 
      #       select(
      #         (.Path | test($video_re; "i") | not) and 
      #         .IsDir == false
      #       ) | 
      #       "\(.Path)\t\(.Size)"
      #     ' | \
      #     while IFS=$'\t' read -r general_file FILE_SIZE; do
            
      #       if [ -z "$general_file" ]; then continue; fi

      #       echo "-----------------------------------------------------"
      #       echo "Found large file for compression: \"$general_file\""
            
      #       # 3. 下载大文件到本地临时目录
      #       echo "Downloading file to compress..."
      #       rclone copy "${REMOTE_PATH}/${general_file}" "$TEMP_DIR" > /dev/null 2>&1
      #       if [ $? -ne 0 ]; then
      #           echo "Error: Failed to download \"$general_file\". Skipping."
      #           continue
      #       fi

      #       LOCAL_FILE_PATH="${TEMP_DIR}/$(basename -- "$general_file")"
      #       BASENAME=$(basename -- "$general_file")
            
      #       # 4. 定义分卷压缩后的文件名
      #       # 例如：input.iso -> input.7z.001, input.7z.002
      #       COMPRESSED_PREFIX="${TEMP_DIR}/${BASENAME}.7z"
            
      #       echo "File size: $(numfmt --to=iec $FILE_SIZE)"
      #       echo "Compressing and splitting into ${VOLUME_SIZE} .7z volumes..."

      #       # 5. 执行 7z 压缩并分卷
      #       # 'a' (Add to archive), '-v4g' (Volume size 4GB), '-m0=lzma2' (启用强大的压缩算法)
      #       7z a -v${VOLUME_SIZE} -m0=lzma2 "$COMPRESSED_PREFIX" "$LOCAL_FILE_PATH"
            
      #       if [ $? -ne 0 ]; then
      #           echo "Error: 7z compression/splitting failed for \"$general_file\". Cleaning up and skipping."
      #           find "$TEMP_DIR" -maxdepth 1 -name "${BASENAME}.7z*" -exec rm -f {} \;
      #           rm -f "$LOCAL_FILE_PATH"
      #           continue
      #       fi
            
      #       # 6. 上传分卷文件到【原始目录】
      #       original_dir=$(dirname "$general_file")
      #       echo "Uploading split volumes to ${REMOTE_PATH}/${original_dir}/"
      #       # 移动所有 .7z 或 .7z.001/.7z.002 等文件
      #       rclone move "$TEMP_DIR" "${REMOTE_PATH}/${original_dir}/" --include "${BASENAME}.7z*" --delete-empty-src-dirs > /dev/null 2>&1
            
      #       # 7. 删除云端的原始大文件
      #       echo "Deleting original file: ${REMOTE_PATH}/${general_file}"
      #       rclone delete "${REMOTE_PATH}/${general_file}" > /dev/null 2>&1

      #       # 8. 清理本地文件
      #       rm -f "$LOCAL_FILE_PATH"

      #     done
          
      #     # 9. 清理临时工作目录
      #     rm -rf "$TEMP_DIR"
      #     echo "-----------------------------------------------------"
      #     echo "General file compression and splitting process completed."
          
      - name: rclone-sync
        run: |
          echo "==========onedrive==========="
          rclone lsf onedrive:
          echo "==========dropbox==========="
          rclone lsf dropbox:
          echo "==========openlist==========="
          rclone lsf openlist:

          # echo "==========  onedrive:  ==========="
          # rclone ls onedrive: \
          #     --exclude "1/**" \
          #     --exclude "2/**" \
          #     --exclude "3/**" \
          #     --exclude "4/**" \
          #     --exclude "5/**" \
          #     --min-size 4G --size-only --order-by size | awk '{printf "%s\t%s\n", $1, $2}' | numfmt --to=iec --field=1 --padding=8
          # echo "==========  onedrive:0  ==========="
          # rclone ls onedrive:0 --min-size 4G --size-only --order-by size | awk '{printf "%s\t%s\n", $1, $2}' | numfmt --to=iec --field=1 --padding=8
          # echo "==========  onedrive:1  ==========="
          # rclone ls onedrive:1 --min-size 4G --size-only --order-by size | awk '{printf "%s\t%s\n", $1, $2}' | numfmt --to=iec --field=1 --padding=8
          # echo "==========  onedrive:2  ==========="
          # rclone ls onedrive:2 --min-size 4G --size-only --order-by size | awk '{printf "%s\t%s\n", $1, $2}' | numfmt --to=iec --field=1 --padding=8
          # echo "==========  onedrive:3  ==========="
          # rclone ls onedrive:3 --min-size 4G --size-only --order-by size | awk '{printf "%s\t%s\n", $1, $2}' | numfmt --to=iec --field=1 --padding=8
          # echo "==========  onedrive:4  ==========="
          # rclone ls onedrive:4 --min-size 4G --size-only --order-by size | awk '{printf "%s\t%s\n", $1, $2}' | numfmt --to=iec --field=1 --padding=8
          # echo "==========  onedrive:5  ==========="
          # rclone ls onedrive:5 --min-size 4G --size-only --order-by size | awk '{printf "%s\t%s\n", $1, $2}' | numfmt --to=iec --field=1 --padding=8
              
          sudo rclone sync onedrive: openlist:baidupanCrypt/onedrive \
              --exclude "backup/notion/**" \
              --exclude "1/**" \
              --exclude "2/**" \
              --exclude "3/**" \
              --exclude "4/**" \
              --exclude "5/**" \
              --progress --fast-list --size-only --transfers 1 --checkers 32  
          curl -s -X POST https://api.telegram.org/bot'${{ secrets.TELEGRAM_BOT_TOKEN }}'/sendMessage -d chat_id='${{ secrets.TELEGRAM_CHAT_ID }}' -d text="github openlist onedrive 任务执行完毕"
      
          sudo rclone sync onedrive:1 openlist:baidupanCrypt/1 --progress --fast-list --size-only --transfers 1 --checkers 32
          curl -s -X POST https://api.telegram.org/bot'${{ secrets.TELEGRAM_BOT_TOKEN }}'/sendMessage -d chat_id='${{ secrets.TELEGRAM_CHAT_ID }}' -d text="github openlist onedrive 1 任务执行完毕"

          sudo rclone sync onedrive:2 openlist:aliyundriveCrypt/2 -vv --progress --fast-list --size-only --transfers 1 --checkers 32
          curl -s -X POST https://api.telegram.org/bot'${{ secrets.TELEGRAM_BOT_TOKEN }}'/sendMessage -d chat_id='${{ secrets.TELEGRAM_CHAT_ID }}' -d text="github openlist onedrive 2 任务执行完毕"

          sudo rclone sync onedrive:3 openlist:aliyundriveCrypt/3 -vv --progress --fast-list --size-only --transfers 1 --checkers 32
          curl -s -X POST https://api.telegram.org/bot'${{ secrets.TELEGRAM_BOT_TOKEN }}'/sendMessage -d chat_id='${{ secrets.TELEGRAM_CHAT_ID }}' -d text="github openlist onedrive 3 任务执行完毕"

          sudo rclone sync onedrive:4 openlist:123pan2Crypt/4 --progress --fast-list --size-only --transfers 1 --checkers 32
          curl -s -X POST https://api.telegram.org/bot'${{ secrets.TELEGRAM_BOT_TOKEN }}'/sendMessage -d chat_id='${{ secrets.TELEGRAM_CHAT_ID }}' -d text="github openlist onedrive 4任务执行完毕"

          sudo rclone sync onedrive:5 openlist:123pan2Crypt/5 --progress --fast-list --size-only --transfers 1 --checkers 32
          curl -s -X POST https://api.telegram.org/bot'${{ secrets.TELEGRAM_BOT_TOKEN }}'/sendMessage -d chat_id='${{ secrets.TELEGRAM_CHAT_ID }}' -d text="github openlist onedrive 5任务执行完毕"
